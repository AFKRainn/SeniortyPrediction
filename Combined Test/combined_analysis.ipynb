{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Analysis: Style Bias × Social Bias\n",
    "\n",
    "This notebook compares results from Test 2 (style bias) and Test 3 (social bias) to answer:\n",
    "- How does an **overstated resume** compare to different **demographic groups**?\n",
    "- Can style compensate for demographic bias? (e.g., Can an understated Caucasian beat an overstated African American?)\n",
    "- Which combination gets the highest/lowest predicted seniority?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seniority ranking for comparison\n",
    "seniority_rank = {'junior': 0, 'mid': 1, 'senior': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results from Both Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test 2 results (style bias)\n",
    "# Try finetuned models first, then LLM if available\n",
    "try:\n",
    "    test2_ft = pd.read_csv(\"../Test 2/test2_finetuned_predictions.csv\")\n",
    "    print(f\"Loaded Test 2 finetuned: {len(test2_ft)} predictions\")\n",
    "except:\n",
    "    test2_ft = None\n",
    "    print(\"Test 2 finetuned predictions not found\")\n",
    "\n",
    "try:\n",
    "    test2_llm = pd.read_csv(\"../Test 2/test2_llm_predictions.csv\")\n",
    "    print(f\"Loaded Test 2 LLM: {len(test2_llm)} predictions\")\n",
    "except:\n",
    "    test2_llm = None\n",
    "    print(\"Test 2 LLM predictions not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test 3 results (social bias)\n",
    "try:\n",
    "    test3_ft = pd.read_csv(\"../Test 3/test3_finetuned_predictions.csv\")\n",
    "    print(f\"Loaded Test 3 finetuned: {len(test3_ft)} predictions\")\n",
    "except:\n",
    "    test3_ft = None\n",
    "    print(\"Test 3 finetuned predictions not found\")\n",
    "\n",
    "try:\n",
    "    test3_llm = pd.read_csv(\"../Test 3/test3_llm_predictions.csv\")\n",
    "    print(f\"Loaded Test 3 LLM: {len(test3_llm)} predictions\")\n",
    "except:\n",
    "    test3_llm = None\n",
    "    print(\"Test 3 LLM predictions not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analysis 1: Style vs Demographics - Who Gets Senior?\n",
    "\n",
    "**What it is:** Compare the rate of \"Senior\" predictions between:\n",
    "- Different styles (overstated, neutral, understated) from Test 2\n",
    "- Different demographics from Test 3\n",
    "\n",
    "**Why we do it:** To see if writing style matters more than demographics (or vice versa).\n",
    "\n",
    "**How to read:** Higher % = model predicts Senior more often for that group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_senior_rate(df):\n",
    "    \"\"\"Calculate % of predictions that are 'senior'\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return None\n",
    "    valid = df[~df['prediction'].isin(['error', 'unknown'])]\n",
    "    return (valid['prediction'] == 'senior').mean() * 100\n",
    "\n",
    "def calc_avg_rank(df):\n",
    "    \"\"\"Calculate average predicted rank (0=junior, 1=mid, 2=senior)\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return None\n",
    "    valid = df[~df['prediction'].isin(['error', 'unknown'])].copy()\n",
    "    valid['pred_rank'] = valid['prediction'].map(seniority_rank)\n",
    "    return valid['pred_rank'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STYLE vs DEMOGRAPHICS: Senior Prediction Rate\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get unique models from available data\n",
    "models = set()\n",
    "if test2_ft is not None:\n",
    "    models.update(test2_ft['model'].unique())\n",
    "if test3_ft is not None:\n",
    "    models.update(test3_ft['model'].unique())\n",
    "if test2_llm is not None:\n",
    "    models.update(test2_llm['model'].unique())\n",
    "if test3_llm is not None:\n",
    "    models.update(test3_llm['model'].unique())\n",
    "\n",
    "for model in sorted(models):\n",
    "    print(f\"\\n{model.upper()}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Style rates from Test 2\n",
    "    print(\"\\nBy STYLE (Test 2):\")\n",
    "    for test2 in [test2_ft, test2_llm]:\n",
    "        if test2 is not None and model in test2['model'].values:\n",
    "            for style in ['overstated', 'neutral', 'understated']:\n",
    "                style_df = test2[(test2['model'] == model) & (test2['style'] == style)]\n",
    "                sr = calc_senior_rate(style_df)\n",
    "                ar = calc_avg_rank(style_df)\n",
    "                if sr is not None:\n",
    "                    print(f\"  {style:<15}: {sr:5.1f}% senior (avg rank: {ar:.2f})\")\n",
    "            break\n",
    "    \n",
    "    # Demographic rates from Test 3\n",
    "    print(\"\\nBy DEMOGRAPHIC (Test 3):\")\n",
    "    for test3 in [test3_ft, test3_llm]:\n",
    "        if test3 is not None and model in test3['model'].values:\n",
    "            for demo in ['caucasian_male', 'caucasian_female', 'african_american_male', 'african_american_female']:\n",
    "                demo_df = test3[(test3['model'] == model) & (test3['demographic'] == demo)]\n",
    "                sr = calc_senior_rate(demo_df)\n",
    "                ar = calc_avg_rank(demo_df)\n",
    "                if sr is not None:\n",
    "                    print(f\"  {demo:<25}: {sr:5.1f}% senior (avg rank: {ar:.2f})\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analysis 2: Can Style Beat Demographics?\n",
    "\n",
    "**What it is:** Compare specific style+demographic combinations:\n",
    "- Overstated (any demographic) vs Understated Caucasian\n",
    "- Understated (any demographic) vs Overstated African American\n",
    "\n",
    "**Why we do it:** To see if how you write matters more than who you are.\n",
    "\n",
    "**How to read:** If overstated gets higher rank than neutral demographic = style > demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CAN STYLE BEAT DEMOGRAPHICS?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for model in sorted(models):\n",
    "    print(f\"\\n{model.upper()}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    style_ranks = {}\n",
    "    demo_ranks = {}\n",
    "    \n",
    "    # Get style ranks\n",
    "    for test2 in [test2_ft, test2_llm]:\n",
    "        if test2 is not None and model in test2['model'].values:\n",
    "            for style in ['overstated', 'neutral', 'understated']:\n",
    "                style_df = test2[(test2['model'] == model) & (test2['style'] == style)]\n",
    "                style_ranks[style] = calc_avg_rank(style_df)\n",
    "            break\n",
    "    \n",
    "    # Get demographic ranks\n",
    "    for test3 in [test3_ft, test3_llm]:\n",
    "        if test3 is not None and model in test3['model'].values:\n",
    "            for demo in ['caucasian_male', 'caucasian_female', 'african_american_male', 'african_american_female']:\n",
    "                demo_df = test3[(test3['model'] == model) & (test3['demographic'] == demo)]\n",
    "                demo_ranks[demo] = calc_avg_rank(demo_df)\n",
    "            break\n",
    "    \n",
    "    if style_ranks and demo_ranks:\n",
    "        # Compare: Overstated vs best demographic\n",
    "        best_demo = max(demo_ranks, key=demo_ranks.get)\n",
    "        worst_demo = min(demo_ranks, key=demo_ranks.get)\n",
    "        \n",
    "        print(f\"\\nRanking comparison (0=junior, 1=mid, 2=senior):\")\n",
    "        print(f\"  Overstated resume:       {style_ranks.get('overstated', 'N/A'):.2f}\")\n",
    "        print(f\"  Best demographic ({best_demo[:10]}): {demo_ranks[best_demo]:.2f}\")\n",
    "        print(f\"  Neutral resume:          {style_ranks.get('neutral', 'N/A'):.2f}\")\n",
    "        print(f\"  Understated resume:      {style_ranks.get('understated', 'N/A'):.2f}\")\n",
    "        print(f\"  Worst demographic ({worst_demo[:10]}): {demo_ranks[worst_demo]:.2f}\")\n",
    "        \n",
    "        # Key comparisons\n",
    "        overstated = style_ranks.get('overstated', 0)\n",
    "        understated = style_ranks.get('understated', 0)\n",
    "        \n",
    "        print(f\"\\n  KEY FINDINGS:\")\n",
    "        if overstated > demo_ranks[best_demo]:\n",
    "            print(f\"  ✓ Overstated beats best demographic (+{overstated - demo_ranks[best_demo]:.2f})\")\n",
    "        else:\n",
    "            print(f\"  ✗ Best demographic beats overstated (+{demo_ranks[best_demo] - overstated:.2f})\")\n",
    "        \n",
    "        if understated < demo_ranks[worst_demo]:\n",
    "            print(f\"  ✓ Understated worse than worst demographic ({understated:.2f} < {demo_ranks[worst_demo]:.2f})\")\n",
    "        else:\n",
    "            print(f\"  ✗ Worst demographic worse than understated ({demo_ranks[worst_demo]:.2f} < {understated:.2f})\")\n",
    "        \n",
    "        style_gap = overstated - understated\n",
    "        demo_gap = demo_ranks[best_demo] - demo_ranks[worst_demo]\n",
    "        print(f\"\\n  Style impact (overstated - understated): {style_gap:+.2f}\")\n",
    "        print(f\"  Demographic impact (best - worst):       {demo_gap:+.2f}\")\n",
    "        \n",
    "        if style_gap > demo_gap:\n",
    "            print(f\"\\n  → STYLE has MORE impact than DEMOGRAPHICS\")\n",
    "        else:\n",
    "            print(f\"\\n  → DEMOGRAPHICS has MORE impact than STYLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analysis 3: Combined Ranking (All Combinations)\n",
    "\n",
    "**What it is:** Rank all style and demographic groups together.\n",
    "\n",
    "**Why we do it:** To see the full picture of what gets the highest predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"COMBINED RANKING: ALL GROUPS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for model in sorted(models):\n",
    "    print(f\"\\n{model.upper()}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    all_groups = []\n",
    "    \n",
    "    # Add style groups\n",
    "    for test2 in [test2_ft, test2_llm]:\n",
    "        if test2 is not None and model in test2['model'].values:\n",
    "            for style in ['overstated', 'neutral', 'understated']:\n",
    "                style_df = test2[(test2['model'] == model) & (test2['style'] == style)]\n",
    "                rank = calc_avg_rank(style_df)\n",
    "                if rank is not None:\n",
    "                    all_groups.append({'group': f\"[STYLE] {style}\", 'avg_rank': rank, 'type': 'style'})\n",
    "            break\n",
    "    \n",
    "    # Add demographic groups\n",
    "    for test3 in [test3_ft, test3_llm]:\n",
    "        if test3 is not None and model in test3['model'].values:\n",
    "            for demo in ['caucasian_male', 'caucasian_female', 'african_american_male', 'african_american_female']:\n",
    "                demo_df = test3[(test3['model'] == model) & (test3['demographic'] == demo)]\n",
    "                rank = calc_avg_rank(demo_df)\n",
    "                if rank is not None:\n",
    "                    all_groups.append({'group': f\"[DEMO] {demo}\", 'avg_rank': rank, 'type': 'demo'})\n",
    "            break\n",
    "    \n",
    "    # Sort and display\n",
    "    all_groups.sort(key=lambda x: x['avg_rank'], reverse=True)\n",
    "    \n",
    "    print(f\"{'Rank':<6} {'Group':<35} {'Avg Predicted Rank'}\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, g in enumerate(all_groups, 1):\n",
    "        print(f\"{i:<6} {g['group']:<35} {g['avg_rank']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualization: Style vs Demographics Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first available model for visualization\n",
    "plot_model = list(models)[0] if models else None\n",
    "\n",
    "if plot_model:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    groups = []\n",
    "    ranks = []\n",
    "    colors = []\n",
    "    \n",
    "    # Style data\n",
    "    for test2 in [test2_ft, test2_llm]:\n",
    "        if test2 is not None and plot_model in test2['model'].values:\n",
    "            for style in ['overstated', 'neutral', 'understated']:\n",
    "                style_df = test2[(test2['model'] == plot_model) & (test2['style'] == style)]\n",
    "                rank = calc_avg_rank(style_df)\n",
    "                if rank is not None:\n",
    "                    groups.append(f\"[S] {style[:5]}\")\n",
    "                    ranks.append(rank)\n",
    "                    colors.append('#3498db')  # Blue for style\n",
    "            break\n",
    "    \n",
    "    # Demographic data\n",
    "    demo_labels = ['Cauc.M', 'Cauc.F', 'AA.M', 'AA.F']\n",
    "    for test3 in [test3_ft, test3_llm]:\n",
    "        if test3 is not None and plot_model in test3['model'].values:\n",
    "            for demo, label in zip(['caucasian_male', 'caucasian_female', 'african_american_male', 'african_american_female'], demo_labels):\n",
    "                demo_df = test3[(test3['model'] == plot_model) & (test3['demographic'] == demo)]\n",
    "                rank = calc_avg_rank(demo_df)\n",
    "                if rank is not None:\n",
    "                    groups.append(f\"[D] {label}\")\n",
    "                    ranks.append(rank)\n",
    "                    colors.append('#e74c3c')  # Red for demographics\n",
    "            break\n",
    "    \n",
    "    if groups:\n",
    "        x = np.arange(len(groups))\n",
    "        bars = ax.bar(x, ranks, color=colors)\n",
    "        \n",
    "        ax.set_ylabel('Avg Predicted Rank (0=Junior, 1=Mid, 2=Senior)')\n",
    "        ax.set_title(f'Style [Blue] vs Demographics [Red] - {plot_model.upper()}')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(groups, rotation=45, ha='right')\n",
    "        ax.axhline(y=1, color='gray', linestyle='--', alpha=0.5, label='Mid level')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No prediction data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "**Interpretation Guide:**\n",
    "\n",
    "1. **If Style impact > Demographic impact:** How you write your resume matters more than your name/perceived identity. This suggests models focus on content/tone rather than demographic cues.\n",
    "\n",
    "2. **If Demographic impact > Style impact:** Your perceived identity (based on name) has more influence than how you present yourself. This indicates social bias in the model.\n",
    "\n",
    "3. **If both are significant:** Both factors play a role, and the worst case would be an understated resume from a disadvantaged demographic group.\n",
    "\n",
    "4. **Ideal case:** Neither should significantly affect predictions - only actual qualifications matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FINAL SUMMARY: STYLE vs SOCIAL BIAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for model in sorted(models):\n",
    "    print(f\"\\n{model.upper()}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Calculate impacts\n",
    "    style_max, style_min = None, None\n",
    "    demo_max, demo_min = None, None\n",
    "    \n",
    "    for test2 in [test2_ft, test2_llm]:\n",
    "        if test2 is not None and model in test2['model'].values:\n",
    "            ranks = []\n",
    "            for style in ['overstated', 'neutral', 'understated']:\n",
    "                r = calc_avg_rank(test2[(test2['model'] == model) & (test2['style'] == style)])\n",
    "                if r is not None:\n",
    "                    ranks.append(r)\n",
    "            if ranks:\n",
    "                style_max, style_min = max(ranks), min(ranks)\n",
    "            break\n",
    "    \n",
    "    for test3 in [test3_ft, test3_llm]:\n",
    "        if test3 is not None and model in test3['model'].values:\n",
    "            ranks = []\n",
    "            for demo in ['caucasian_male', 'caucasian_female', 'african_american_male', 'african_american_female']:\n",
    "                r = calc_avg_rank(test3[(test3['model'] == model) & (test3['demographic'] == demo)])\n",
    "                if r is not None:\n",
    "                    ranks.append(r)\n",
    "            if ranks:\n",
    "                demo_max, demo_min = max(ranks), min(ranks)\n",
    "            break\n",
    "    \n",
    "    if style_max is not None and demo_max is not None:\n",
    "        style_impact = style_max - style_min\n",
    "        demo_impact = demo_max - demo_min\n",
    "        \n",
    "        print(f\"Style impact (max - min):       {style_impact:.3f}\")\n",
    "        print(f\"Demographic impact (max - min): {demo_impact:.3f}\")\n",
    "        \n",
    "        if style_impact > demo_impact * 1.5:\n",
    "            print(f\"\\n→ STYLE DOMINATES: Writing tone is the major factor\")\n",
    "        elif demo_impact > style_impact * 1.5:\n",
    "            print(f\"\\n→ DEMOGRAPHICS DOMINATE: Social bias is the major factor\")\n",
    "        else:\n",
    "            print(f\"\\n→ BOTH MATTER: Style and demographics have similar impact\")\n",
    "    else:\n",
    "        print(\"Insufficient data for comparison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
