{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1043d8",
   "metadata": {},
   "source": [
    "## GPT Embeddings Baseline (OpenRouter)\n",
    "\n",
    "This notebook reproduces the same baseline flow as `baseline.ipynb`, but **replaces TF-IDF with embeddings** from OpenRouter using the model **`openai/text-embedding-ada-002`**.\n",
    "\n",
    "High-level steps:\n",
    "- Load `Baseline/cleaned_resumes.csv`\n",
    "- Auto-select the same feature columns (exclude IDs + target)\n",
    "- Embed **each column separately**, then concatenate the embeddings into one feature matrix\n",
    "- Train a **Random Forest** classifier and evaluate with a **confusion matrix plot**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15b319",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "We import standard libraries, the HTTP client (`requests`) for calling OpenRouter, and scikit-learn utilities for training + evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e620aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59f8322",
   "metadata": {},
   "source": [
    "## 2. OpenRouter config (API key + model)\n",
    "\n",
    "This cell:\n",
    "- Reads your OpenRouter API key from environment variables\n",
    "- Defines the embedding model `openai/text-embedding-ada-002`\n",
    "- Sets the OpenRouter base URL (OpenAI-compatible)\n",
    "\n",
    "Nothing sensitive is printed (we only print which env var name was used).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a70ae252",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Missing API key. Set OPENROUTER_API_KEY in your environment (preferred). If you are using an OpenAI-compatible key name, OPENAI_API_KEY is also checked.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m val, env_name\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing API key. Set OPENROUTER_API_KEY in your environment (preferred). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are using an OpenAI-compatible key name, OPENAI_API_KEY is also checked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[0;32m---> 20\u001b[0m OPENROUTER_API_KEY, API_KEY_SOURCE \u001b[38;5;241m=\u001b[39m \u001b[43m_get_openrouter_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing API key from env var: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_KEY_SOURCE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing OpenRouter base URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOPENROUTER_BASE_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36m_get_openrouter_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m val, env_name\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing API key. Set OPENROUTER_API_KEY in your environment (preferred). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are using an OpenAI-compatible key name, OPENAI_API_KEY is also checked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Missing API key. Set OPENROUTER_API_KEY in your environment (preferred). If you are using an OpenAI-compatible key name, OPENAI_API_KEY is also checked."
     ]
    }
   ],
   "source": [
    "OPENROUTER_BASE_URL = os.getenv(\"OPENROUTER_BASE_URL\", \"https://openrouter.ai/api/v1\")\n",
    "EMBEDDING_MODEL = \"openai/text-embedding-ada-002\"\n",
    "\n",
    "# To avoid extremely long payloads, we truncate each field to a safe character limit.\n",
    "# If you want to be stricter/looser, change this value.\n",
    "MAX_CHARS_PER_FIELD = 8000\n",
    "\n",
    "\n",
    "def _get_openrouter_api_key():\n",
    "    for env_name in [\"OPENROUTER_API_KEY\", \"OPENAI_API_KEY\"]:\n",
    "        val = os.getenv(env_name)\n",
    "        if val:\n",
    "            return val, env_name\n",
    "    raise RuntimeError(\n",
    "        \"Missing API key. Set OPENROUTER_API_KEY in your environment (preferred). \"\n",
    "        \"If you are using an OpenAI-compatible key name, OPENAI_API_KEY is also checked.\"\n",
    "    )\n",
    "\n",
    "\n",
    "OPENROUTER_API_KEY, API_KEY_SOURCE = _get_openrouter_api_key()\n",
    "print(f\"Using API key from env var: {API_KEY_SOURCE}\")\n",
    "print(f\"Using OpenRouter base URL: {OPENROUTER_BASE_URL}\")\n",
    "print(f\"Embedding model: {EMBEDDING_MODEL}\")\n",
    "\n",
    "\n",
    "def _truncate_text(s: str, max_chars: int = MAX_CHARS_PER_FIELD) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s)\n",
    "    if len(s) <= max_chars:\n",
    "        return s\n",
    "    return s[:max_chars]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc36713",
   "metadata": {},
   "source": [
    "## 3. Load the dataset + select columns\n",
    "\n",
    "This cell:\n",
    "- Loads `cleaned_resumes.csv` from the Baseline folder (with a small path check)\n",
    "- Auto-selects the same feature columns as `baseline.ipynb`\n",
    "- Prepares `X_df` (features) and `y` (target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ff009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the CSV without assuming the current working directory\n",
    "candidate_paths = [Path(\"cleaned_resumes.csv\"), Path(\"Baseline\") / \"cleaned_resumes.csv\"]\n",
    "for p in candidate_paths:\n",
    "    if p.exists():\n",
    "        data_path = p\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Could not find cleaned_resumes.csv. Tried: {[str(x) for x in candidate_paths]}\")\n",
    "\n",
    "print(f\"Loading: {data_path}\")\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "TARGET = \"experience_level\"\n",
    "ID_COLS = {\"name\", \"email\", \"linkedin\", \"github\", \"summary_count\"}\n",
    "\n",
    "feature_cols = [c for c in df.columns if c != TARGET and c not in ID_COLS]\n",
    "\n",
    "# Ensure text values are strings (embeddings API expects strings)\n",
    "for col in feature_cols:\n",
    "    df[col] = df[col].astype(str).fillna(\"\")\n",
    "\n",
    "X_df = df[feature_cols]\n",
    "y = df[TARGET]\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Using {len(feature_cols)} feature columns: {feature_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f65208",
   "metadata": {},
   "source": [
    "## 4. OpenRouter embedding helper\n",
    "\n",
    "This cell defines a small helper that:\n",
    "- Calls the OpenRouter **OpenAI-compatible** `/embeddings` endpoint\n",
    "- Batches requests (to avoid huge payloads)\n",
    "- Retries on temporary failures\n",
    "- Deduplicates identical strings to reduce the number of paid embedding inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _openrouter_embeddings_request(inputs, *, model=EMBEDDING_MODEL, timeout_s=90):\n",
    "    url = f\"{OPENROUTER_BASE_URL.rstrip('/')}/embeddings\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"input\": inputs,\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, json=payload, timeout=timeout_s)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f\"OpenRouter embeddings error {resp.status_code}: {resp.text[:500]}\")\n",
    "\n",
    "    data = resp.json()\n",
    "    items = data.get(\"data\", [])\n",
    "\n",
    "    # Ensure we return embeddings in the same order as inputs\n",
    "    items_sorted = sorted(items, key=lambda x: x.get(\"index\", 0))\n",
    "    embeddings = [it[\"embedding\"] for it in items_sorted]\n",
    "\n",
    "    if len(embeddings) != len(inputs):\n",
    "        raise RuntimeError(f\"Expected {len(inputs)} embeddings, got {len(embeddings)}\")\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def embed_texts_openrouter(texts, *, batch_size=64, max_retries=5, retry_sleep_s=1.5):\n",
    "    # Truncate to protect against overly long fields\n",
    "    texts = [_truncate_text(t) for t in texts]\n",
    "\n",
    "    # Deduplicate to reduce API calls\n",
    "    unique_texts = list(dict.fromkeys(texts))\n",
    "\n",
    "    unique_embeddings = []\n",
    "    for start in range(0, len(unique_texts), batch_size):\n",
    "        batch = unique_texts[start : start + batch_size]\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                batch_embs = _openrouter_embeddings_request(batch)\n",
    "                unique_embeddings.extend(batch_embs)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "                sleep_for = retry_sleep_s * (2 ** attempt)\n",
    "                time.sleep(sleep_for)\n",
    "\n",
    "    if len(unique_embeddings) != len(unique_texts):\n",
    "        raise RuntimeError(\"Internal error: embedding count mismatch after batching\")\n",
    "\n",
    "    lookup = {t: emb for t, emb in zip(unique_texts, unique_embeddings)}\n",
    "    dense = np.array([lookup[t] for t in texts], dtype=np.float32)\n",
    "\n",
    "    return dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdde3c2",
   "metadata": {},
   "source": [
    "## 5. Build the embedding feature matrix\n",
    "\n",
    "We embed **each selected column** separately (same idea as multi-column TF-IDF), then concatenate all embeddings into a single matrix `X_embed`.\n",
    "\n",
    "This keeps the resume fields separated in the representation while still producing one vector per resume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ffb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_embeds = []\n",
    "\n",
    "for col in feature_cols:\n",
    "    print(f\"Embedding column: {col}\")\n",
    "    texts = X_df[col].tolist()\n",
    "    col_vecs = embed_texts_openrouter(texts, batch_size=64)\n",
    "    print(f\"  -> {col_vecs.shape}\")\n",
    "    column_embeds.append(col_vecs)\n",
    "\n",
    "X_embed = np.concatenate(column_embeds, axis=1)\n",
    "print(f\"Final embedding matrix shape: {X_embed.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4fbd06",
   "metadata": {},
   "source": [
    "## 6. Train/test split + Random Forest training\n",
    "\n",
    "We split embeddings into train/test (stratified by `experience_level`) and train a Random Forest.\n",
    "\n",
    "Like `baseline.ipynb`, we give extra weight to **`mid`** to encourage the model to focus more on separating the middle class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff330bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_embed, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "class_weights = {'junior': 1.0, 'mid': 3.0, 'senior': 1.0}\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight=class_weights,\n",
    ")\n",
    "\n",
    "print(f\"Training Random Forest with class weights: {class_weights}\")\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Training complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39380d82",
   "metadata": {},
   "source": [
    "## 7. Evaluation + confusion matrix\n",
    "\n",
    "We evaluate the Random Forest on the test set and visualize the confusion matrix to see where it confuses `junior`, `mid`, and `senior`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c919dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "labels = ['junior', 'mid', 'senior']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title(f'Confusion Matrix: RF on ada-002 embeddings (Acc: {acc:.2%})')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
