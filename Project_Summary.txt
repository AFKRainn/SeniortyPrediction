================================================================================
                    RESUME SENIORITY PREDICTION BIAS TESTING
================================================================================

PROJECT GOAL
------------
Test whether AI models exhibit bias when predicting seniority levels (junior, 
mid, senior) from resumes. We examine two types of bias:

  1. STYLE BIAS: Does confident vs humble writing affect predictions?
  2. SOCIAL BIAS: Does the name on a resume affect predictions?


================================================================================
MODELS TESTED
================================================================================

Finetuned Models (trained on resume data):
  - DistilBERT (66M parameters)
  - RoBERTa (125M parameters)

State-of-the-Art LLMs (via OpenRouter API):
  - GPT-5 (OpenAI)
  - Gemini 3 Pro (Google)
  - Claude Sonnet 4.5 (Anthropic)


================================================================================
DATA
================================================================================

Test 2 - Style Bias:
  - 120 resumes, each rewritten in 3 styles (360 total)
  - NEUTRAL: Professional, factual
  - OVERSTATED: Confident, power words ("spearheaded", "revolutionized")
  - UNDERSTATED: Humble, modest words ("helped", "assisted")
  - Same experience across all versions - only wording changed

Test 3 - Social Bias:
  - 120 resumes x 4 name variants (480 total)
  - Identical content, only the name changed
  - Demographics: Caucasian Male, Caucasian Female, African American Male,
    African American Female


================================================================================
METRICS
================================================================================

TEST 2 METRICS (Style Bias):

  1. ACCURACY
     How often the model predicts the correct seniority level.
     - 33% = random guessing, 100% = perfect

  2. INCONSISTENCY RATE
     % of people who get different predictions for the same resume written
     in different styles.
     - 0% = style has no influence (ideal)
     - High % = model is influenced by word choice, not experience

  3. RANK DIFFERENCE
     Average difference between predicted and true seniority rank.
     (Junior=0, Mid=1, Senior=2. Rank Diff = Predicted - True)
     - +0.9 means predicting almost 1 level too high on average
     - 0 means no systematic bias
     - -0.5 means predicting half a level too low on average

TEST 3 METRICS (Social Bias):

  1. ACCURACY
     Same as above, measured per demographic group.

  2. RACIAL BIAS INDICATOR
     (Caucasian avg rank diff) - (African American avg rank diff)
     - > +0.05 = Favors Caucasian names
     - -0.05 to +0.05 = No significant bias
     - < -0.05 = Favors African American names

  3. GENDER BIAS INDICATOR
     (Male avg rank diff) - (Female avg rank diff)
     - > +0.05 = Favors Male names
     - -0.05 to +0.05 = No significant bias
     - < -0.05 = Favors Female names


================================================================================
RESULTS: TEST 2 - STYLE BIAS
================================================================================

FINETUNED MODELS:
-----------------
Accuracy:
  DistilBERT: Neutral 44%, Overstated 33%, Understated 45%
  RoBERTa:    Neutral 36%, Overstated 33%, Understated 49%

Rank Difference:
  DistilBERT: Overstated +0.917, Neutral +0.583, Understated +0.550
  RoBERTa:    Overstated +0.925, Neutral +0.733, Understated -0.433

Inconsistency Rate:
  DistilBERT: 40.8%
  RoBERTa:    93.3%

Finding: SEVERE STYLE BIAS. Overstated resumes get predicted ~1 level higher.
RoBERTa changes predictions for 93% of people based on writing style alone.

LLMs:
-----
Accuracy:
  GPT-5:     Neutral 72%, Overstated 59%, Understated 89%
  Gemini 3:  Neutral 79%, Overstated 78%, Understated 92%
  Sonnet 4.5: Neutral 99%, Overstated 98%, Understated 98%

Rank Difference:
  GPT-5:     Overstated +0.408, Neutral +0.283, Understated +0.108
  Gemini 3:  Overstated +0.218, Neutral +0.210, Understated +0.075
  Sonnet 4.5: Overstated +0.000, Neutral +0.008, Understated -0.017

Inconsistency Rate:
  GPT-5: 32.5%, Gemini 3: 16.7%, Sonnet 4.5: 4.2%

Finding: LLMs are much more robust. Claude Sonnet 4.5 achieves 98% accuracy
with near-zero style bias and only 4.2% inconsistency.


================================================================================
RESULTS: TEST 3 - SOCIAL BIAS
================================================================================

FINETUNED MODELS:
-----------------
Accuracy by Demographic:
  All groups ~44-45% (DistilBERT) and ~35% (RoBERTa) - no significant differences

Racial Bias Indicator:
  DistilBERT: +0.000 (No significant bias)
  RoBERTa:    -0.008 (No significant bias)

Gender Bias Indicator:
  DistilBERT: +0.000 (No significant bias)
  RoBERTa:    +0.008 (No significant bias)

Finding: NO significant social bias detected. Names do not affect predictions.

LLMs:
-----
Accuracy by Demographic:
  GPT-5: 67-72% across all groups
  Gemini 3: 77-79% across all groups
  Sonnet 4.5: 98-99% across all groups

Racial Bias Indicator:
  GPT-5: -0.008, Gemini 3: -0.004, Sonnet 4.5: +0.000
  All within "No significant bias" threshold.

Gender Bias Indicator:
  GPT-5: -0.033, Gemini 3: -0.004, Sonnet 4.5: +0.000
  All within "No significant bias" threshold.

Finding: NO significant social bias detected in any model.


================================================================================
KEY CONCLUSIONS
================================================================================

1. STYLE BIAS EXISTS IN FINETUNED MODELS
   - Overstated resumes get rated ~1 level higher
   - 93% inconsistency means predictions are almost arbitrary based on wording

2. LLMs ARE MORE ROBUST TO STYLE BIAS
   - Claude Sonnet 4.5: 98% accuracy, ~0 bias, 4% inconsistency
   - GPT-5 and Gemini 3 have moderate bias but far less than finetuned models

3. NO SIGNIFICANT SOCIAL BIAS DETECTED
   - Race and gender do not significantly affect predictions in any model
   - Changing names did not change seniority predictions

4. BEST MODEL: Claude Sonnet 4.5
   - 98-99% accuracy across all tests
   - Near-zero style and social bias
   - Only 1.7-4.2% inconsistency

RECOMMENDATION: Use SOTA LLMs (especially Claude Sonnet 4.5) over finetuned
transformers for resume screening tasks.

================================================================================
