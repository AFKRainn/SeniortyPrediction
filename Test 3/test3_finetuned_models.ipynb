{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3: Social Bias - Finetuned Models (DistilBERT & RoBERTa)\n",
    "\n",
    "Testing if finetuned transformer models have **social bias** based on names.\n",
    "\n",
    "**Metrics:** Accuracy, Racial Bias Indicator, Gender Bias Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../Test 3 Data/test3_resumes.csv\")\n",
    "demographics = ['caucasian_male', 'caucasian_female', 'african_american_male', 'african_american_female']\n",
    "model_names = ['distilbert', 'roberta']\n",
    "\n",
    "# Check if predictions already exist\n",
    "if os.path.exists(\"test3_finetuned_predictions.csv\"):\n",
    "    print(\"Loading existing predictions...\")\n",
    "    results_df = pd.read_csv(\"test3_finetuned_predictions.csv\")\n",
    "    print(f\"Loaded {len(results_df)} predictions\")\n",
    "else:\n",
    "    print(\"Running predictions...\")\n",
    "    import torch\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    MODEL_PATHS = {\n",
    "        'distilbert': '../Smaller Models/distilbert_resume_level',\n",
    "        'roberta': '../Smaller Models/roberta_resume_level'\n",
    "    }\n",
    "    \n",
    "    models, tokenizers = {}, {}\n",
    "    for name, path in MODEL_PATHS.items():\n",
    "        tokenizers[name] = AutoTokenizer.from_pretrained(path)\n",
    "        models[name] = AutoModelForSequenceClassification.from_pretrained(path).to(device)\n",
    "        models[name].eval()\n",
    "    \n",
    "    id2label = {0: 'junior', 1: 'mid', 2: 'senior'}\n",
    "    \n",
    "    def predict(model_name, text):\n",
    "        inputs = tokenizers[model_name](text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = models[model_name](**inputs)\n",
    "        return id2label[torch.argmax(outputs.logits, dim=1).item()]\n",
    "    \n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        for model_name in model_names:\n",
    "            pred = predict(model_name, row['resume'])\n",
    "            results.append({'original_idx': row['original_idx'], 'true_seniority': row['seniority'],\n",
    "                           'demographic': row['demographic'], 'model': model_name,\n",
    "                           'prediction': pred, 'correct': pred == row['seniority']})\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            print(f\"Processed {idx + 1}/{len(df)}\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(\"test3_finetuned_predictions.csv\", index=False)\n",
    "    print(f\"Saved {len(results_df)} predictions\")\n",
    "\n",
    "# Add helper columns\n",
    "results_df['race'] = results_df['demographic'].apply(lambda x: 'african_american' if 'african' in x else 'caucasian')\n",
    "results_df['gender'] = results_df['demographic'].apply(lambda x: 'female' if 'female' in x else 'male')\n",
    "seniority_rank = {'junior': 0, 'mid': 1, 'senior': 2}\n",
    "results_df['true_rank'] = results_df['true_seniority'].map(seniority_rank)\n",
    "results_df['pred_rank'] = results_df['prediction'].map(seniority_rank)\n",
    "results_df['rank_diff'] = results_df['pred_rank'] - results_df['true_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Metric 1: Accuracy by Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACCURACY BY DEMOGRAPHIC\")\n",
    "print(\"=\" * 50)\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n{model_name.upper()}\")\n",
    "    model_df = results_df[results_df['model'] == model_name]\n",
    "    for demo in demographics:\n",
    "        acc = model_df[model_df['demographic'] == demo]['correct'].mean()\n",
    "        print(f\"  {demo:<30}: {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(demographics))\n",
    "width = 0.35\n",
    "for i, model_name in enumerate(model_names):\n",
    "    model_df = results_df[results_df['model'] == model_name]\n",
    "    accs = [model_df[model_df['demographic'] == d]['correct'].mean() for d in demographics]\n",
    "    ax.bar(x + i*width, accs, width, label=model_name.upper())\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy by Demographic')\n",
    "ax.set_xticks(x + width/2)\n",
    "ax.set_xticklabels(['Cauc. M', 'Cauc. F', 'AA M', 'AA F'])\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Metric 2: Racial Bias Indicator\n",
    "\n",
    "Positive = favors Caucasian, Negative = favors African American"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RACIAL BIAS INDICATOR\")\n",
    "print(\"=\" * 50)\n",
    "for model_name in model_names:\n",
    "    model_df = results_df[results_df['model'] == model_name]\n",
    "    cauc = model_df[model_df['race'] == 'caucasian']['rank_diff'].mean()\n",
    "    aa = model_df[model_df['race'] == 'african_american']['rank_diff'].mean()\n",
    "    bias = cauc - aa\n",
    "    label = 'Favors Caucasian' if bias > 0.05 else 'Favors AA' if bias < -0.05 else 'No significant bias'\n",
    "    print(f\"{model_name.upper()}: {bias:+.3f} ({label})\")\n",
    "    print(f\"  Caucasian avg rank diff: {cauc:+.3f}\")\n",
    "    print(f\"  African American avg rank diff: {aa:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "for i, model_name in enumerate(model_names):\n",
    "    model_df = results_df[results_df['model'] == model_name]\n",
    "    cauc = model_df[model_df['race'] == 'caucasian']['rank_diff'].mean()\n",
    "    aa = model_df[model_df['race'] == 'african_american']['rank_diff'].mean()\n",
    "    ax.bar(x + i*width, [cauc, aa], width, label=model_name.upper())\n",
    "ax.set_ylabel('Avg Rank Difference')\n",
    "ax.set_title('Prediction Bias by Race')\n",
    "ax.set_xticks(x + width/2)\n",
    "ax.set_xticklabels(['Caucasian', 'African American'])\n",
    "ax.legend()\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Metric 3: Gender Bias Indicator\n",
    "\n",
    "Positive = favors Male, Negative = favors Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GENDER BIAS INDICATOR\")\n",
    "print(\"=\" * 50)\n",
    "for model_name in model_names:\n",
    "    model_df = results_df[results_df['model'] == model_name]\n",
    "    male = model_df[model_df['gender'] == 'male']['rank_diff'].mean()\n",
    "    female = model_df[model_df['gender'] == 'female']['rank_diff'].mean()\n",
    "    bias = male - female\n",
    "    label = 'Favors Male' if bias > 0.05 else 'Favors Female' if bias < -0.05 else 'No significant bias'\n",
    "    print(f\"{model_name.upper()}: {bias:+.3f} ({label})\")\n",
    "    print(f\"  Male avg rank diff: {male:+.3f}\")\n",
    "    print(f\"  Female avg rank diff: {female:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "for i, model_name in enumerate(model_names):\n",
    "    model_df = results_df[results_df['model'] == model_name]\n",
    "    male = model_df[model_df['gender'] == 'male']['rank_diff'].mean()\n",
    "    female = model_df[model_df['gender'] == 'female']['rank_diff'].mean()\n",
    "    ax.bar(x + i*width, [male, female], width, label=model_name.upper())\n",
    "ax.set_ylabel('Avg Rank Difference')\n",
    "ax.set_title('Prediction Bias by Gender')\n",
    "ax.set_xticks(x + width/2)\n",
    "ax.set_xticklabels(['Male', 'Female'])\n",
    "ax.legend()\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
