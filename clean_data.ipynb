{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2045b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key: personal_info\n",
      "Type: dict\n",
      "Dict keys: ['name', 'email', 'phone', 'location', 'summary', 'linkedin', 'github']\n",
      "  - name: str\n",
      "  - email: str\n",
      "  - phone: str\n",
      "  - location: dict\n",
      "    Dict keys: ['city', 'country', 'remote_preference']\n",
      "  - summary: str\n",
      "  - linkedin: str\n",
      "  - github: str\n",
      "\n",
      "Key: experience\n",
      "Type: list\n",
      "List length: 1\n",
      "Item 0 type: dict\n",
      "Item 0 keys: ['company', 'company_info', 'title', 'level', 'employment_type', 'dates', 'responsibilities', 'technical_environment']\n",
      "  - company: str\n",
      "  - company_info: dict\n",
      "    Dict keys: ['industry', 'size']\n",
      "  - title: str\n",
      "  - level: str\n",
      "  - employment_type: str\n",
      "  - dates: dict\n",
      "    Dict keys: ['start', 'end', 'duration']\n",
      "  - responsibilities: list\n",
      "    List length: 1, first item type: str\n",
      "  - technical_environment: dict\n",
      "    Dict keys: ['technologies', 'methodologies', 'tools']\n",
      "\n",
      "Key: education\n",
      "Type: list\n",
      "List length: 2\n",
      "Item 0 type: dict\n",
      "Item 0 keys: ['degree', 'institution', 'dates', 'achievements']\n",
      "  - degree: dict\n",
      "    Dict keys: ['level', 'field', 'major']\n",
      "  - institution: dict\n",
      "    Dict keys: ['name', 'location', 'accreditation']\n",
      "  - dates: dict\n",
      "    Dict keys: ['start', 'expected_graduation']\n",
      "  - achievements: dict\n",
      "    Dict keys: ['gpa', 'honors', 'relevant_coursework']\n",
      "Item 1 type: dict\n",
      "Item 1 keys: ['degree', 'institution', 'dates', 'achievements']\n",
      "  - degree: dict\n",
      "    Dict keys: ['level', 'field', 'major']\n",
      "  - institution: dict\n",
      "    Dict keys: ['name', 'location', 'accreditation']\n",
      "  - dates: dict\n",
      "    Dict keys: ['start', 'expected_graduation']\n",
      "  - achievements: dict\n",
      "    Dict keys: ['gpa', 'honors', 'relevant_coursework']\n",
      "\n",
      "Key: skills\n",
      "Type: dict\n",
      "Dict keys: ['technical', 'languages']\n",
      "  - technical: dict\n",
      "    Dict keys: ['programming_languages', 'frameworks', 'databases', 'cloud']\n",
      "  - languages: list\n",
      "    List length: 1, first item type: dict\n",
      "    First item keys: ['name', 'level']\n",
      "\n",
      "Key: projects\n",
      "Type: list\n",
      "List length: 1\n",
      "Item 0 type: dict\n",
      "Item 0 keys: ['name', 'description', 'technologies', 'role', 'url', 'impact']\n",
      "  - name: str\n",
      "  - description: str\n",
      "  - technologies: list\n",
      "    List length: 1, first item type: str\n",
      "  - role: str\n",
      "  - url: str\n",
      "  - impact: str\n",
      "\n",
      "Key: certifications\n",
      "Type: str\n",
      "Value preview: \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSONL file and inspect the structure of each key\n",
    "with open('master_resumes_original.jsonl', 'r', encoding='utf-8') as f:\n",
    "    first_line = f.readline()\n",
    "    record = json.loads(first_line.strip())\n",
    "    \n",
    "    for key in record.keys():\n",
    "        print(f\"\\nKey: {key}\")\n",
    "        value = record[key]\n",
    "        \n",
    "        # Show the type and structure\n",
    "        print(f\"Type: {type(value).__name__}\")\n",
    "        \n",
    "        if isinstance(value, dict):\n",
    "            print(f\"Dict keys: {list(value.keys())}\")\n",
    "            # Show a sample of nested structure\n",
    "            for sub_key, sub_value in value.items():\n",
    "                print(f\"  - {sub_key}: {type(sub_value).__name__}\")\n",
    "                if isinstance(sub_value, dict):\n",
    "                    print(f\"    Dict keys: {list(sub_value.keys())}\")\n",
    "                elif isinstance(sub_value, list) and sub_value:\n",
    "                    print(f\"    List length: {len(sub_value)}, first item type: {type(sub_value[0]).__name__}\")\n",
    "                    if isinstance(sub_value[0], dict):\n",
    "                        print(f\"    First item keys: {list(sub_value[0].keys())}\")\n",
    "        \n",
    "        elif isinstance(value, list):\n",
    "            print(f\"List length: {len(value)}\")\n",
    "            if value:\n",
    "                # Show all items in the list, not just the first one\n",
    "                for idx, item in enumerate(value):\n",
    "                    print(f\"Item {idx} type: {type(item).__name__}\")\n",
    "                    if isinstance(item, dict):\n",
    "                        print(f\"Item {idx} keys: {list(item.keys())}\")\n",
    "                        # Show nested structure of each item\n",
    "                        for sub_key, sub_value in item.items():\n",
    "                            print(f\"  - {sub_key}: {type(sub_value).__name__}\")\n",
    "                            if isinstance(sub_value, dict):\n",
    "                                print(f\"    Dict keys: {list(sub_value.keys())}\")\n",
    "                            elif isinstance(sub_value, list) and sub_value:\n",
    "                                print(f\"    List length: {len(sub_value)}, first item type: {type(sub_value[0]).__name__}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Value preview: {str(value)[:100]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a19494b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4817 records\n",
      "Created 11 columns\n",
      "\n",
      "Column names: ['name', 'email', 'summary', 'linkedin', 'github', 'experience', 'education', 'skills', 'projects', 'certifications', 'summary_count']\n",
      "\n",
      "First few rows:\n",
      "           name         email  \\\n",
      "0       Unknown       Unknown   \n",
      "1       Unknown       Unknown   \n",
      "2  Not Provided  Not Provided   \n",
      "3       Unknown       Unknown   \n",
      "4                               \n",
      "\n",
      "                                             summary      linkedin  \\\n",
      "0  Python Developer with experience in Python, Te...       Unknown   \n",
      "1  Experienced Operations Manager with expertise ...           NaN   \n",
      "2  Software Proficiency in various languages and ...  Not Provided   \n",
      "3  Experienced Operations Manager with expertise ...           NaN   \n",
      "4                                                                    \n",
      "\n",
      "         github                                         experience  \\\n",
      "0       Unknown  [{\"company\": \"Fresher\", \"company_info\": {\"indu...   \n",
      "1           NaN  [{\"company\": \"Delta Controls, Dubai FZCO\", \"co...   \n",
      "2  Not Provided  [{\"company\": \"Parkar Consulting and Labs\", \"co...   \n",
      "3           NaN  [{\"company\": \"Delta Controls, Dubai FZCO\", \"co...   \n",
      "4                [{\"company\": \"Atos Syntel\", \"company_info\": {\"...   \n",
      "\n",
      "                                           education  \\\n",
      "0  [{\"degree\": {\"level\": \"ME\", \"field\": \"Computer...   \n",
      "1  [{\"degree\": {\"level\": \"B.E\", \"field\": \"Electro...   \n",
      "2  [{\"degree\": {\"level\": \"B.E.\", \"field\": \"Not Pr...   \n",
      "3  [{\"degree\": {\"level\": \"B.E\", \"field\": \"Electro...   \n",
      "4  [{\"degree\": {\"level\": \"Bachelor of Engineering...   \n",
      "\n",
      "                                              skills  \\\n",
      "0  {\"technical\": {\"programming_languages\": [{\"nam...   \n",
      "1  {\"technical\": {\"project_management\": [{\"name\":...   \n",
      "2  {\"technical\": {\"programming_languages\": [{\"nam...   \n",
      "3  {\"technical\": {\"project_management\": [{\"name\":...   \n",
      "4  {\"technical\": {\"programming_languages\": [{\"nam...   \n",
      "\n",
      "                                            projects  \\\n",
      "0  [{\"name\": \"Unknown\", \"description\": \"Unknown\",...   \n",
      "1  [{\"name\": \"FGP/WPMP\", \"description\": \"Led syst...   \n",
      "2  [{\"name\": \"FPGA Implementation\", \"description\"...   \n",
      "3  [{\"name\": \"FGP/WPMP\", \"description\": \"Led syst...   \n",
      "4                                                 []   \n",
      "\n",
      "                                      certifications  summary_count  \n",
      "0                                                 \"\"            100  \n",
      "1                                                 \"\"            232  \n",
      "2                                                 \"\"            167  \n",
      "3                                                 \"\"            232  \n",
      "4  \"{\\\"name\\\": \\\"ESD Program\\\", \\\"issuer\\\": \\\"Zen...              0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_resume_data(record):\n",
    "    \"\"\"\n",
    "    Extract and clean resume data - just parse fields simply.\n",
    "    \"\"\"\n",
    "    cleaned = {}\n",
    "\n",
    "    # Process personal_info\n",
    "    personal_info = record.get('personal_info', {})\n",
    "    if isinstance(personal_info, dict):\n",
    "        for key, value in personal_info.items():\n",
    "            # Skip location - we don't want it\n",
    "            if key == 'location':\n",
    "                continue\n",
    "            # Add simple values directly\n",
    "            if isinstance(value, (str, int, float, bool, type(None))):\n",
    "                cleaned[key] = value\n",
    "\n",
    "    # Simply process experience - just put the value as JSON string, no extra extraction\n",
    "    experience = record.get('experience', [])\n",
    "    cleaned['experience'] = json.dumps(experience)\n",
    "\n",
    "    # Process education - convert to JSON string\n",
    "    education = record.get('education', [])\n",
    "    cleaned['education'] = json.dumps(education)\n",
    "\n",
    "    # Process skills - convert to JSON string\n",
    "    skills = record.get('skills')\n",
    "    cleaned['skills'] = json.dumps(skills) if skills is not None else json.dumps({})\n",
    "\n",
    "    # Process projects - convert to JSON string\n",
    "    projects = record.get('projects', [])\n",
    "    cleaned['projects'] = json.dumps(projects)\n",
    "\n",
    "    # Process certifications - convert to JSON string\n",
    "    certifications = record.get('certifications')\n",
    "    cleaned['certifications'] = json.dumps(certifications) if certifications is not None else json.dumps([])\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "# Read all records from JSONL and clean them\n",
    "all_records = []\n",
    "with open('master_resumes_original.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            record = json.loads(line.strip())\n",
    "            cleaned_record = clean_resume_data(record)\n",
    "            all_records.append(cleaned_record)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_records)\n",
    "\n",
    "# get length of the 'summary' column and create a new column with summary_count\n",
    "df['summary_count'] = df['summary'].fillna('').apply(len)\n",
    "# remove the phone column\n",
    "df = df.drop(columns=['phone'])\n",
    "\n",
    "print(f\"Processed {len(all_records)} records\")\n",
    "print(f\"Created {len(df.columns)} columns\")\n",
    "print(f\"\\nColumn names: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f3940143",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_values = {\"Unknown\", \"Not Provided\", \"Not Available\", \"N/A\", \"unknown\", \"not provided\", \"\"}\n",
    "\n",
    "def has_invalid_start_end(experience_json):\n",
    "    try:\n",
    "        exp_list = json.loads(experience_json)\n",
    "        for exp in exp_list:\n",
    "            dates = exp.get(\"dates\", {})\n",
    "            start = dates.get(\"start\", \"\")\n",
    "            end = dates.get(\"end\", \"\")\n",
    "            if start in invalid_values or end in invalid_values:\n",
    "                return True\n",
    "        return False\n",
    "    except Exception:\n",
    "        # If can't parse or not list, err on the side of exclusion\n",
    "        return True\n",
    "\n",
    "df = df[~df[\"experience\"].apply(has_invalid_start_end)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e01a4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows left after deletion: 4634\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total rows left after deletion: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "PRESENT_DATE = \"2025-12-12\"\n",
    "\n",
    "def parse_date(date_str):\n",
    "    # Assumes date format is YYYY-MM-DD or \"present\"\n",
    "    if isinstance(date_str, str) and date_str.strip().lower() == \"present\":\n",
    "        try:\n",
    "            return datetime.strptime(PRESENT_DATE, \"%Y-%m-%d\")\n",
    "        except:\n",
    "            return None\n",
    "    try:\n",
    "        return datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def calculate_duration(start_date, end_date):\n",
    "    start = parse_date(start_date)\n",
    "    end = parse_date(end_date)\n",
    "    if start and end:\n",
    "        duration_years = (end - start).days / 365.25\n",
    "        return max(0, duration_years)\n",
    "    return 0\n",
    "\n",
    "level_map = {\"junior\": 1, \"mid\": 2, \"senior\": 3}\n",
    "\n",
    "def extract_seniority_and_experience(exp_json):\n",
    "    try:\n",
    "        experiences = json.loads(exp_json)\n",
    "    except:\n",
    "        return {\n",
    "            \"experience_level\": \"unknown\",\n",
    "            \"last_experience_only\": \"N/A\",\n",
    "            \"total_experience_time\": \"0 Years\",\n",
    "            \"last_experience_time\": \"0 Years\",\n",
    "            \"target_job_title\": \"\",\n",
    "            \"updated_experience_json\": exp_json\n",
    "        }\n",
    "\n",
    "    if not isinstance(experiences, list) or len(experiences) == 0:\n",
    "        return {\n",
    "            \"experience_level\": \"unknown\",\n",
    "            \"last_experience_only\": \"N/A\",\n",
    "            \"total_experience_time\": \"0 Years\",\n",
    "            \"last_experience_time\": \"0 Years\",\n",
    "            \"target_job_title\": \"\",\n",
    "            \"updated_experience_json\": exp_json\n",
    "        }\n",
    "\n",
    "    # Preprocess: normalize levels, calculate durations and update duration field\n",
    "    for exp in experiences:\n",
    "        dates = exp.get('dates', {})\n",
    "        start = dates.get('start', '')\n",
    "        end = dates.get('end', '')\n",
    "        \n",
    "        duration_val = calculate_duration(start, end)\n",
    "        exp['duration_calc'] = duration_val\n",
    "        \n",
    "        # Update the duration field in the dates object\n",
    "        if 'dates' not in exp:\n",
    "            exp['dates'] = {}\n",
    "        exp['dates']['duration'] = f\"{duration_val:.2f} years\"\n",
    "        \n",
    "        # Lowercase `level` for robustness\n",
    "        if 'level' in exp and isinstance(exp['level'], str):\n",
    "            exp['level'] = exp['level'].lower()\n",
    "        if 'title' in exp and exp['title'] is not None:\n",
    "            exp['title'] = str(exp['title']).strip().lower()\n",
    "        else:\n",
    "            exp['title'] = \"\"\n",
    "\n",
    "    # Determine last_experience_only flag based on number of experiences\n",
    "    if len(experiences) == 1:\n",
    "        last_experience_only_flag = \"Only last Experience listed\"\n",
    "    else:\n",
    "        last_experience_only_flag = \"Multiple Experiences listed\"\n",
    "\n",
    "    # Selection Logic\n",
    "    if len(experiences) == 1:\n",
    "        most_recent_exp = experiences[0]\n",
    "    else:\n",
    "        # More than one experience; find which is the \"most recent\" (should be the one with \"present\", if any)\n",
    "        def is_present(exp):\n",
    "            end = exp.get('dates', {}).get('end', '')\n",
    "            return isinstance(end, str) and end.strip().lower() == \"present\"\n",
    "        # 'present' always marks the last experience\n",
    "        present_exps = [exp for exp in experiences if is_present(exp)]\n",
    "        if present_exps:\n",
    "            most_recent_exp = present_exps[0]\n",
    "        else:\n",
    "            # Fall back to max end date\n",
    "            def exp_end_date(exp):\n",
    "                return parse_date(exp.get('dates', {}).get('end', '')) or datetime.min\n",
    "            most_recent_exp = max(experiences, key=exp_end_date)\n",
    "\n",
    "        temp_exp = most_recent_exp\n",
    "        temp_title = temp_exp.get('title', '').lower()\n",
    "        temp_level = temp_exp.get('level', '').lower()\n",
    "        temp_level_rank = level_map.get(temp_level, 0)\n",
    "\n",
    "        for exp in experiences:\n",
    "            if exp is temp_exp:\n",
    "                continue\n",
    "            exp_title = exp.get('title', '').lower()\n",
    "            exp_level = exp.get('level', '').lower()\n",
    "            exp_level_rank = level_map.get(exp_level, 0)\n",
    "            if exp_title == temp_title and exp_level_rank > temp_level_rank:\n",
    "                temp_level_rank = exp_level_rank\n",
    "                temp_exp = exp\n",
    "                temp_level = exp_level\n",
    "        \n",
    "        most_recent_exp = temp_exp\n",
    "\n",
    "    # Extract target level BEFORE clearing it\n",
    "    experience_level = most_recent_exp.get('level', 'unknown').lower()\n",
    "    \n",
    "    # Extract target job title BEFORE any modifications\n",
    "    target_job_title = most_recent_exp.get('title', '')\n",
    "    \n",
    "    # -------------------------------------------------------------\n",
    "    # Clear the 'level' ONLY from the chosen experience\n",
    "    # -------------------------------------------------------------\n",
    "    most_recent_exp['level'] = \"\"\n",
    "    \n",
    "    total_experience_years = sum(exp.get('duration_calc', 0) for exp in experiences)\n",
    "    last_experience_years = most_recent_exp.get('duration_calc', 0)\n",
    "\n",
    "    # Return updated structure including the modified list (with CLEARED level for target ONLY)\n",
    "    return {\n",
    "        \"experience_level\": experience_level,\n",
    "        \"last_experience_only\": last_experience_only_flag,\n",
    "        \"total_experience_time\": f\"{round(total_experience_years, 2)} Years\",\n",
    "        \"last_experience_time\": f\"{round(last_experience_years, 2)} Years\",\n",
    "        \"target_job_title\": target_job_title,\n",
    "        \"updated_experience_json\": json.dumps(experiences)\n",
    "    }\n",
    "\n",
    "# Now apply to the DataFrame\n",
    "\n",
    "df_results = df['experience'].apply(extract_seniority_and_experience)\n",
    "df['experience_level'] = df_results.apply(lambda x: x['experience_level'])\n",
    "df['last_experience_only'] = df_results.apply(lambda x: x['last_experience_only'])\n",
    "df['total_experience_time'] = df_results.apply(lambda x: x['total_experience_time'])\n",
    "df['last_experience_time'] = df_results.apply(lambda x: x['last_experience_time'])\n",
    "df['job title'] = df_results.apply(lambda x: x['target_job_title'])\n",
    "# Update the experience column with the modified JSON (calculated duration + cleared level)\n",
    "df['experience'] = df_results.apply(lambda x: x.get('updated_experience_json', df['experience'].iloc[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b7817397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the experience JSON and convert to readable text format\n",
    "def parse_experience_to_text(experience_json):\n",
    "    \"\"\"\n",
    "    Parse the experience JSON and convert it to a readable text format.\n",
    "    Each experience is labeled as \"Experience 1:\", \"Experience 2:\", etc.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        experiences = json.loads(experience_json)\n",
    "        if not experiences or not isinstance(experiences, list):\n",
    "            return \"\"\n",
    "        \n",
    "        text_parts = []\n",
    "        for i, exp in enumerate(experiences, 1):\n",
    "            exp_text = f\"Experience {i}: \"\n",
    "            \n",
    "            # Add company\n",
    "            if exp.get('company'):\n",
    "                exp_text += f\"Company: {exp['company']}. \"\n",
    "            \n",
    "            # Add title\n",
    "            if exp.get('title'):\n",
    "                exp_text += f\"Title: {exp['title']}. \"\n",
    "            \n",
    "            # Add level (if present)\n",
    "            if exp.get('level'):\n",
    "                exp_text += f\"Level: {exp['level']}. \"\n",
    "            \n",
    "            # Add employment type\n",
    "            if exp.get('employment_type'):\n",
    "                exp_text += f\"Employment Type: {exp['employment_type']}. \"\n",
    "            \n",
    "            # Add dates\n",
    "            if exp.get('dates'):\n",
    "                dates = exp['dates']\n",
    "                if dates.get('start'):\n",
    "                    exp_text += f\"Start Date: {dates['start']}. \"\n",
    "                if dates.get('end'):\n",
    "                    exp_text += f\"End Date: {dates['end']}. \"\n",
    "                if dates.get('duration'):\n",
    "                    exp_text += f\"Duration: {dates['duration']}. \"\n",
    "            \n",
    "            # Add responsibilities\n",
    "            if exp.get('responsibilities') and isinstance(exp['responsibilities'], list):\n",
    "                responsibilities = ' '.join(exp['responsibilities'])\n",
    "                exp_text += f\"Responsibilities: {responsibilities}. \"\n",
    "            \n",
    "            # Add technical environment\n",
    "            if exp.get('technical_environment'):\n",
    "                tech_env = exp['technical_environment']\n",
    "                if tech_env.get('technologies') and isinstance(tech_env['technologies'], list):\n",
    "                    technologies = ', '.join(tech_env['technologies'])\n",
    "                    exp_text += f\"Technologies: {technologies}. \"\n",
    "                if tech_env.get('methodologies') and isinstance(tech_env['methodologies'], list):\n",
    "                    methodologies = ', '.join(tech_env['methodologies'])\n",
    "                    exp_text += f\"Methodologies: {methodologies}. \"\n",
    "                if tech_env.get('tools') and isinstance(tech_env['tools'], list):\n",
    "                    tools = ', '.join(tech_env['tools'])\n",
    "                    exp_text += f\"Tools: {tools}. \"\n",
    "            \n",
    "            # Add company info\n",
    "            if exp.get('company_info'):\n",
    "                company_info = exp['company_info']\n",
    "                if company_info.get('industry'):\n",
    "                    exp_text += f\"Industry: {company_info['industry']}. \"\n",
    "                if company_info.get('size'):\n",
    "                    exp_text += f\"Company Size: {company_info['size']}. \"\n",
    "            \n",
    "            text_parts.append(exp_text.strip())\n",
    "        \n",
    "        return ' '.join(text_parts)\n",
    "    \n",
    "    except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "        return \"\"\n",
    "\n",
    "# Apply the parsing function to the experience column\n",
    "df['experience'] = df['experience'].apply(parse_experience_to_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d26c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse education JSON to text\n",
    "def parse_education_to_text(education_str):\n",
    "    \"\"\"\n",
    "    Parse the education JSON string and convert it to a readable text format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(education_str) or education_str == '':\n",
    "            return \"\"\n",
    "        \n",
    "        education_list = json.loads(education_str)\n",
    "        if not isinstance(education_list, list):\n",
    "            return \"\"\n",
    "        \n",
    "        text_parts = []\n",
    "        for idx, edu in enumerate(education_list, 1):\n",
    "            if not isinstance(edu, dict):\n",
    "                continue\n",
    "            \n",
    "            edu_text = f\"Education {idx}: \"\n",
    "            \n",
    "            # Add degree information\n",
    "            if edu.get('degree'):\n",
    "                degree = edu['degree']\n",
    "                if degree.get('level'):\n",
    "                    edu_text += f\"Degree Level: {degree['level']}. \"\n",
    "                if degree.get('field'):\n",
    "                    edu_text += f\"Field: {degree['field']}. \"\n",
    "                if degree.get('major'):\n",
    "                    edu_text += f\"Major: {degree['major']}. \"\n",
    "            \n",
    "            # Add institution information\n",
    "            if edu.get('institution'):\n",
    "                institution = edu['institution']\n",
    "                if institution.get('name'):\n",
    "                    edu_text += f\"Institution: {institution['name']}. \"\n",
    "                if institution.get('location'):\n",
    "                    edu_text += f\"Location: {institution['location']}. \"\n",
    "                if institution.get('accreditation'):\n",
    "                    edu_text += f\"Accreditation: {institution['accreditation']}. \"\n",
    "            \n",
    "            # Add dates\n",
    "            if edu.get('dates'):\n",
    "                dates = edu['dates']\n",
    "                if dates.get('start'):\n",
    "                    edu_text += f\"Start Date: {dates['start']}. \"\n",
    "                if dates.get('end'):\n",
    "                    edu_text += f\"End Date: {dates['end']}. \"\n",
    "                if dates.get('expected_graduation'):\n",
    "                    edu_text += f\"Expected Graduation: {dates['expected_graduation']}. \"\n",
    "            \n",
    "            # Add achievements\n",
    "            if edu.get('achievements'):\n",
    "                achievements = edu['achievements']\n",
    "                if achievements.get('gpa'):\n",
    "                    edu_text += f\"GPA: {achievements['gpa']}. \"\n",
    "                if achievements.get('honors'):\n",
    "                    edu_text += f\"Honors: {achievements['honors']}. \"\n",
    "                if achievements.get('relevant_coursework') and isinstance(achievements['relevant_coursework'], list):\n",
    "                    coursework = ', '.join(achievements['relevant_coursework'])\n",
    "                    if coursework:\n",
    "                        edu_text += f\"Relevant Coursework: {coursework}. \"\n",
    "            \n",
    "            text_parts.append(edu_text.strip())\n",
    "        \n",
    "        return ' '.join(text_parts)\n",
    "    \n",
    "    except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "        return \"\"\n",
    "\n",
    "# Apply the parsing function to the education column\n",
    "df['education'] = df['education'].apply(parse_education_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a8cf8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse skills JSON to text\n",
    "def parse_skills_to_text(skills_json):\n",
    "    \"\"\"\n",
    "    Parse the skills JSON structure into a readable text format.\n",
    "    \"\"\"\n",
    "    if pd.isna(skills_json) or skills_json == '':\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        if isinstance(skills_json, str):\n",
    "            skills = json.loads(skills_json)\n",
    "        else:\n",
    "            skills = skills_json\n",
    "        \n",
    "        text_parts = []\n",
    "        \n",
    "        # Parse technical skills\n",
    "        if skills.get('technical'):\n",
    "            technical = skills['technical']\n",
    "            \n",
    "            # Programming languages\n",
    "            if technical.get('programming_languages') and isinstance(technical['programming_languages'], list):\n",
    "                for lang in technical['programming_languages']:\n",
    "                    if lang.get('name'):\n",
    "                        lang_text = f\"Programming Language: {lang['name']}\"\n",
    "                        if lang.get('level'):\n",
    "                            lang_text += f\" (Level: {lang['level']})\"\n",
    "                        text_parts.append(lang_text + \". \")\n",
    "            \n",
    "            # Frameworks\n",
    "            if technical.get('frameworks') and isinstance(technical['frameworks'], list):\n",
    "                for framework in technical['frameworks']:\n",
    "                    if framework.get('name'):\n",
    "                        framework_text = f\"Framework: {framework['name']}\"\n",
    "                        if framework.get('level'):\n",
    "                            framework_text += f\" (Level: {framework['level']})\"\n",
    "                        text_parts.append(framework_text + \". \")\n",
    "            \n",
    "            # Databases\n",
    "            if technical.get('databases') and isinstance(technical['databases'], list):\n",
    "                for db in technical['databases']:\n",
    "                    if db.get('name'):\n",
    "                        db_text = f\"Database: {db['name']}\"\n",
    "                        if db.get('level'):\n",
    "                            db_text += f\" (Level: {db['level']})\"\n",
    "                        text_parts.append(db_text + \". \")\n",
    "            \n",
    "            # Cloud\n",
    "            if technical.get('cloud') and isinstance(technical['cloud'], list):\n",
    "                for cloud in technical['cloud']:\n",
    "                    if isinstance(cloud, dict) and cloud.get('name'):\n",
    "                        cloud_text = f\"Cloud: {cloud['name']}\"\n",
    "                        if cloud.get('level'):\n",
    "                            cloud_text += f\" (Level: {cloud['level']})\"\n",
    "                        text_parts.append(cloud_text + \". \")\n",
    "                    elif isinstance(cloud, str):\n",
    "                        text_parts.append(f\"Cloud: {cloud}. \")\n",
    "        \n",
    "        # Parse languages\n",
    "        if skills.get('languages') and isinstance(skills['languages'], list):\n",
    "            for language in skills['languages']:\n",
    "                if isinstance(language, dict) and language.get('name'):\n",
    "                    lang_text = f\"Language: {language['name']}\"\n",
    "                    if language.get('level'):\n",
    "                        lang_text += f\" (Level: {language['level']})\"\n",
    "                    text_parts.append(lang_text + \". \")\n",
    "                elif isinstance(language, str):\n",
    "                    text_parts.append(f\"Language: {language}. \")\n",
    "        \n",
    "        return ' '.join(text_parts).strip()\n",
    "    \n",
    "    except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "        return \"\"\n",
    "\n",
    "# Apply the parsing function to the skills column\n",
    "df['skills'] = df['skills'].apply(parse_skills_to_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1bdb668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse projects column from JSON to text\n",
    "def parse_projects_to_text(projects_str):\n",
    "    \"\"\"\n",
    "    Parse the projects JSON string into a readable text format.\n",
    "    If empty or invalid, return \"No Projects made\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(projects_str) or str(projects_str).strip() == '' or str(projects_str).strip() == '[]':\n",
    "            return \"No Projects made\"\n",
    "        \n",
    "        projects = json.loads(projects_str)\n",
    "        \n",
    "        if not projects or not isinstance(projects, list) or len(projects) == 0:\n",
    "            return \"No Projects made\"\n",
    "        \n",
    "        text_parts = []\n",
    "        \n",
    "        for idx, project in enumerate(projects, 1):\n",
    "            if not isinstance(project, dict):\n",
    "                continue\n",
    "            \n",
    "            project_text = f\"Project {idx}: \"\n",
    "            \n",
    "            # Project name\n",
    "            if project.get('name'):\n",
    "                project_text += f\"{project['name']}. \"\n",
    "            \n",
    "            # Description\n",
    "            if project.get('description'):\n",
    "                project_text += f\"Description: {project['description']}. \"\n",
    "            \n",
    "            # Technologies\n",
    "            if project.get('technologies') and isinstance(project['technologies'], list):\n",
    "                tech_list = [tech for tech in project['technologies'] if tech]\n",
    "                if tech_list:\n",
    "                    project_text += f\"Technologies: {', '.join(tech_list)}. \"\n",
    "            \n",
    "            # Role\n",
    "            if project.get('role'):\n",
    "                project_text += f\"Role: {project['role']}. \"\n",
    "            \n",
    "            # URL\n",
    "            if project.get('url'):\n",
    "                project_text += f\"URL: {project['url']}. \"\n",
    "            \n",
    "            # Impact\n",
    "            if project.get('impact'):\n",
    "                project_text += f\"Impact: {project['impact']}. \"\n",
    "            \n",
    "            text_parts.append(project_text.strip())\n",
    "        \n",
    "        if not text_parts:\n",
    "            return \"No Projects made\"\n",
    "        \n",
    "        return ' '.join(text_parts).strip()\n",
    "    \n",
    "    except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "        return \"No Projects made\"\n",
    "\n",
    "# Apply the parsing function to the projects column\n",
    "df['projects'] = df['projects'].apply(parse_projects_to_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b553f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle certifications column - convert to string and handle empty values\n",
    "def clean_certifications(cert_value):\n",
    "    \"\"\"\n",
    "    Convert certifications to string and handle empty values.\n",
    "    Returns 'No certifications' for empty/null values.\n",
    "    \"\"\"\n",
    "    # Handle NaN, None, or empty strings\n",
    "    if pd.isna(cert_value) or cert_value == '' or (isinstance(cert_value, str) and cert_value.strip() == ''):\n",
    "        return \"No certifications\"\n",
    "    \n",
    "    # Check for common empty list representations\n",
    "    if cert_value in ['[]', '[ ]', 'null', 'None', \"\", \" \", '\"\"']:\n",
    "        return \"No certifications\"\n",
    "    \n",
    "    # Convert to string and strip whitespace\n",
    "    cert_str = str(cert_value).strip()\n",
    "    \n",
    "    # Return the cleaned string or default if empty after stripping\n",
    "    return cert_str if cert_str else \"No certifications\"\n",
    "\n",
    "# Apply the cleaning function to the certifications column\n",
    "df['certifications'] = df['certifications'].apply(clean_certifications)\n",
    "\n",
    "# Also fill any remaining NaN values as a safety measure\n",
    "df['certifications'] = df['certifications'].fillna(\"No certifications\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9912de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4626\n"
     ]
    }
   ],
   "source": [
    "# Remove all rows where the 'summary' column is empty or contains only whitespace\n",
    "df = df[df['summary'].astype(str).str.strip() != '']\n",
    "\n",
    "# Show the number of rows left\n",
    "print(len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e562e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df.to_csv('cleaned_resumes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7b3ed737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick 700 records of a senior, 700 of a mid, 700 of a junior, and save that file in ./Baseline/cleaned_resumes.csv\n",
    "# Sample 700 records from each experience level\n",
    "senior_df = df[df['experience_level'] == 'senior']\n",
    "mid_df = df[df['experience_level'] == 'mid']\n",
    "junior_df = df[df['experience_level'] == 'junior']\n",
    "\n",
    "senior_sample = senior_df.sample(n=min(700, len(senior_df)), random_state=42)\n",
    "mid_sample = mid_df.sample(n=min(700, len(mid_df)), random_state=42)\n",
    "junior_sample = junior_df.sample(n=min(700, len(junior_df)), random_state=42)\n",
    "\n",
    "# Combine the samples\n",
    "balanced_df = pd.concat([senior_sample, mid_sample, junior_sample], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a1b68f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2100 records to ./Baseline/cleaned_resumes.csv\n",
      "\n",
      "Experience level distribution:\n",
      "experience_level\n",
      "senior    700\n",
      "mid       700\n",
      "junior    700\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Save to the specified location\n",
    "balanced_df.to_csv('./Baseline/cleaned_resumes.csv', index=False)\n",
    "balanced_df.to_csv('./Smaller Models/cleaned_resumes.csv', index=False)\n",
    "balanced_df.to_csv('./Big Models/cleaned_resumes.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Saved {len(balanced_df)} records to ./Baseline/cleaned_resumes.csv\")\n",
    "print(f\"\\nExperience level distribution:\")\n",
    "print(balanced_df['experience_level'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c547d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
