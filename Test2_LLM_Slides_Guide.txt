================================================================================
              TEST 2: STYLE BIAS - LLMs (SLIDES GUIDE)
================================================================================

WHAT WE TESTED
--------------
Question: Do SOTA LLMs have style bias in seniority predictions?
Models: GPT-5, Gemini 3 Pro, Claude Sonnet 4.5 (via OpenRouter)
Data: 120 people x 3 writing styles = 360 resumes


================================================================================
METRIC 1: ACCURACY
================================================================================

What it measures: % of correct seniority predictions per style.

Results:
  GPT-5:      Neutral 72%, Overstated 59%, Understated 89%
  Gemini 3:   Neutral 79%, Overstated 78%, Understated 92%
  Sonnet 4.5: Neutral 99%, Overstated 98%, Understated 98%

Key insight: Claude Sonnet 4.5 achieves ~98% accuracy regardless of style.
GPT-5 accuracy drops for overstated resumes, indicating some style sensitivity.


================================================================================
METRIC 2: INCONSISTENCY RATE
================================================================================

What it measures: % of people who get different predictions across styles.
Why it matters: Same experience should = same prediction.

Results:
  GPT-5:      32.5% inconsistent
  Gemini 3:   16.7% inconsistent
  Sonnet 4.5: 4.2% inconsistent

Key insight: Sonnet 4.5 only changes predictions for 4% of people based on
style - far better than finetuned models (93%) and other LLMs.


================================================================================
METRIC 3: RANK DIFFERENCE
================================================================================

What it measures: How much the model over/underestimates seniority.
Formula: Predicted rank - True rank (Junior=0, Mid=1, Senior=2)

Results:
  GPT-5:      Overstated +0.408, Neutral +0.283, Understated +0.108
  Gemini 3:   Overstated +0.218, Neutral +0.210, Understated +0.075
  Sonnet 4.5: Overstated +0.000, Neutral +0.008, Understated -0.017

Key insight: Sonnet 4.5 has essentially zero rank bias across all styles.
GPT-5 still shows moderate overestimation for overstated resumes (+0.408).


================================================================================
CONCLUSION
================================================================================

LLMs ARE MORE ROBUST THAN FINETUNED MODELS:
- Claude Sonnet 4.5: 98% accuracy, ~0 bias, 4% inconsistency (best performer)
- Gemini 3: Good accuracy (78-92%), moderate bias, 17% inconsistency
- GPT-5: Moderate bias toward overstated resumes, 33% inconsistency

SOTA LLMs, especially Claude Sonnet 4.5, are suitable for fair seniority
classification with minimal style bias.

================================================================================
