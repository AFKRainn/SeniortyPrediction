{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generated Summaries Quality Metrics\n",
        "\n",
        "Three simple metrics to validate our 4,626 generated summaries are good quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Load data\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "with open('generated_summaries.json', 'r', encoding='utf-8') as f:\n",
        "    summaries = json.load(f)\n",
        "\n",
        "df = pd.read_csv('cleaned_resumes.csv')\n",
        "df['generated_summary'] = df.index.astype(str).map(summaries)\n",
        "\n",
        "print(f\"Loaded {len(summaries)} generated summaries\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric 1: Word Count\n",
        "Are the summaries a reasonable length? (Not too short, not too long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_counts = df['generated_summary'].dropna().apply(lambda x: len(str(x).split()))\n",
        "\n",
        "print(f\"Average word count: {word_counts.mean():.0f} words\")\n",
        "print(f\"Range: {word_counts.min()} to {word_counts.max()} words\")\n",
        "print(f\"Summaries too short (<50 words): {(word_counts < 50).sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric 2: Skill Coverage\n",
        "Do the summaries mention skills from the original resume? (Content faithfulness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_skill_coverage(row):\n",
        "    skills_str = row['skills']\n",
        "    summary = str(row['generated_summary']).lower()\n",
        "    if pd.isna(skills_str): return np.nan\n",
        "    \n",
        "    skills = re.findall(r\":\\s*([^(]+?)\\s*\\(Level:\", str(skills_str))\n",
        "    skills = [s.strip().lower() for s in skills if s.strip()]\n",
        "    if not skills: return np.nan\n",
        "    \n",
        "    mentioned = sum(1 for skill in skills if skill in summary)\n",
        "    return (mentioned / len(skills)) * 100\n",
        "\n",
        "df['skill_coverage'] = df.apply(get_skill_coverage, axis=1)\n",
        "coverage = df['skill_coverage'].dropna()\n",
        "\n",
        "print(f\"Average skill coverage: {coverage.mean():.1f}%\")\n",
        "print(f\"Summaries with >30% coverage: {(coverage > 30).sum()} / {len(coverage)} ({(coverage > 30).sum()/len(coverage)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric 3: Years Accuracy\n",
        "When the summary mentions years of experience, is it accurate?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_years(text):\n",
        "    match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(?:\\+)?\\s*years?', str(text).lower())\n",
        "    return float(match.group(1)) if match else np.nan\n",
        "\n",
        "df['original_years'] = df['total_experience_time'].str.replace(' Years', '').astype(float)\n",
        "df['summary_years'] = df['generated_summary'].apply(extract_years)\n",
        "\n",
        "valid = df.dropna(subset=['original_years', 'summary_years'])\n",
        "valid['diff'] = abs(valid['summary_years'] - valid['original_years'])\n",
        "\n",
        "print(f\"Summaries where years could be compared: {len(valid)}\")\n",
        "print(f\"Accurate within Â±2 years: {(valid['diff'] <= 2).sum()} / {len(valid)} ({(valid['diff'] <= 2).sum()/len(valid)*100:.1f}%)\")\n",
        "print(f\"Average difference: {valid['diff'].mean():.1f} years\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
