{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RoBERTa Resume Experience Classifier\n",
        "\n",
        "This notebook fine-tunes **RoBERTa-base** to predict **experience_level** (junior/mid/senior) from resume data.\n",
        "\n",
        "**Approach:**\n",
        "- Concatenates all resume columns into a single text sequence\n",
        "- Fine-tunes `roberta-base` for 3-class classification\n",
        "- Uses HuggingFace Trainer with stratified train/test split\n",
        "- Evaluates with accuracy, F1-score, and confusion matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# Check if running on CPU or CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data\n",
        "\n",
        "Load the cleaned resumes CSV and inspect the data distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TARGET_COL = \"experience_level\"\n",
        "\n",
        "df = pd.read_csv(\"cleaned_resumes.csv\", engine=\"python\")\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "print(\"\\nTarget distribution:\\n\", df[TARGET_COL].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare Text Data\n",
        "\n",
        "Concatenate all resume columns (except the target label) into a single text string per row. Each column is prefixed with its name in brackets for context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_value(v):\n",
        "    \"\"\"Convert any cell to a clean string.\"\"\"\n",
        "    if pd.isna(v):\n",
        "        return \"\"\n",
        "    s = str(v)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def row_to_text(row, target_col):\n",
        "    parts = []\n",
        "    for col, val in row.items():\n",
        "        if col == target_col:\n",
        "            continue\n",
        "        s = clean_value(val)\n",
        "        if s:\n",
        "            parts.append(f\"[{col}] {s}\")\n",
        "    return \" \".join(parts)\n",
        "\n",
        "df[\"text\"] = df.apply(lambda r: row_to_text(r, TARGET_COL), axis=1)\n",
        "\n",
        "print(df[\"text\"].iloc[0][:600])\n",
        "print(\"\\nAverage text length (chars):\", int(df[\"text\"].str.len().mean()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Label Mappings\n",
        "\n",
        "Map the target labels (junior, mid, senior) to integer IDs for classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = sorted(df[TARGET_COL].dropna().unique().tolist())\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "\n",
        "df[\"label\"] = df[TARGET_COL].map(label2id)\n",
        "\n",
        "print(\"Labels:\", labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train/Test Split\n",
        "\n",
        "Create stratified 80/20 train/test split to ensure balanced class distribution in both sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"label\"]\n",
        ")\n",
        "\n",
        "print(\"Train:\", train_df.shape, \"Test:\", test_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tokenization\n",
        "\n",
        "Load the RoBERTa tokenizer and tokenize the train/test text data. Text is truncated/padded to max 512 tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_NAME = \"roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "MAX_LEN = 512\n",
        "\n",
        "def tokenize(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=MAX_LEN\n",
        "    )\n",
        "\n",
        "train_enc = tokenize(train_df[\"text\"].tolist())\n",
        "test_enc = tokenize(test_df[\"text\"].tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create PyTorch Datasets\n",
        "\n",
        "Wrap the tokenized data and labels into PyTorch Dataset objects for the Trainer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResumeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = ResumeDataset(train_enc, train_df[\"label\"].tolist())\n",
        "test_dataset = ResumeDataset(test_enc, test_df[\"label\"].tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Pre-trained Model\n",
        "\n",
        "Load RoBERTa with a classification head for 3 classes (junior/mid/senior).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Setup\n",
        "\n",
        "Define metrics computation, training arguments, and initialize the Trainer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, y_true = eval_pred\n",
        "    y_pred = np.argmax(logits, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\")\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"roberta_resume_level\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=5,\n",
        "\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation & Results\n",
        "\n",
        "Run predictions on the test set and display accuracy, F1-score, classification report, and confusion matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = trainer.predict(test_dataset)\n",
        "\n",
        "y_true = test_df[\"label\"].to_numpy()\n",
        "y_pred = np.argmax(pred.predictions, axis=1)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Macro-F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=labels))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "conf_mat = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.title(\"Confusion Matrix - RoBERTa\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "undefined.undefined.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
