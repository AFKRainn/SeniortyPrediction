{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Config\n",
    "MODEL = \"openai/gpt-5\"\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "OPENROUTER_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "if not OPENROUTER_API_KEY:\n",
    "    raise ValueError(\"Set OPENROUTER_API_KEY environment variable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"cleaned_resumes.csv\")\n",
    "\n",
    "# Get 20% stratified test set\n",
    "_, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"experience_level\"])\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "print(test_df[\"experience_level\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to include in the prompt (exclude target and personal info)\n",
    "EXCLUDE_COLS = {\"experience_level\", \"name\", \"email\", \"linkedin\", \"github\", \"summary_count\", \"total_experience_time\", \"last_experience_time\", \"last_experience_only\"}\n",
    "\n",
    "def build_resume_text(row):\n",
    "    \"\"\"Build resume text from row data.\"\"\"\n",
    "    parts = []\n",
    "    for col in row.index:\n",
    "        if col not in EXCLUDE_COLS:\n",
    "            val = str(row[col]).strip()\n",
    "            if val and val.lower() != \"nan\":\n",
    "                parts.append(f\"{col}: {val}\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "def call_api(resume_text):\n",
    "    \"\"\"Call API and return the predicted label (junior/mid/senior).\"\"\"\n",
    "    prompt = f\"\"\"You are classifying job candidates by seniority level.\n",
    "Based on the resume below, respond with exactly ONE word: junior, mid, or senior.\n",
    "\n",
    "{resume_text}\n",
    "\n",
    "Your answer (one word only):\"\"\"\n",
    "    \n",
    "    payload = json.dumps({\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        # \"max_tokens\": 16\n",
    "    }).encode(\"utf-8\")\n",
    "    \n",
    "    req = urllib.request.Request(\n",
    "        OPENROUTER_URL,\n",
    "        data=payload,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(req, timeout=120) as resp:\n",
    "            result = json.loads(resp.read().decode(\"utf-8\"))\n",
    "    except urllib.error.HTTPError as e:\n",
    "        error_body = e.read().decode(\"utf-8\")\n",
    "        raise Exception(f\"HTTP {e.code}: {error_body}\")\n",
    "    \n",
    "    response = result[\"choices\"][0][\"message\"][\"content\"].strip().lower()\n",
    "    \n",
    "    # Extract valid label\n",
    "    if \"junior\" in response:\n",
    "        return \"junior\"\n",
    "    elif \"mid\" in response:\n",
    "        return \"mid\"\n",
    "    elif \"senior\" in response:\n",
    "        return \"senior\"\n",
    "    else:\n",
    "        return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classification\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    true_label = row[\"experience_level\"].strip().lower()\n",
    "    resume_text = build_resume_text(row)\n",
    "    \n",
    "    try:\n",
    "        pred_label = call_api(resume_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Row {idx} failed: {e}\")\n",
    "        pred_label = \"unknown\"\n",
    "    \n",
    "    y_true.append(true_label)\n",
    "    y_pred.append(pred_label)\n",
    "    \n",
    "    if (idx + 1) % 50 == 0:\n",
    "        print(f\"Processed {idx + 1}/{len(test_df)}\")\n",
    "\n",
    "print(f\"\\nDone! {len(y_pred)} predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "labels = [\"junior\", \"mid\", \"senior\"]\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\\n\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, labels=labels, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Junior', 'Mid', 'Senior'],\n",
    "            yticklabels=['Junior', 'Mid', 'Senior'])\n",
    "plt.title(f'Confusion Matrix - {MODEL}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
